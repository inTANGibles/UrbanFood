{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## OSM与本地的建筑数据对比"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "origin_data/5. Buildings_OSM: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mDataSourceError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# 读取数据\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# gdf_factories = gpd.read_file(\"path/to/your_processing_points.shp\").to_crs(epsg=32632)\u001B[39;00m\n\u001B[0;32m      7\u001B[0m gdf_buildings \u001B[38;5;241m=\u001B[39m gpd\u001B[38;5;241m.\u001B[39mread_file(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124morigin_data/5. Buildings\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mto_crs(epsg\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32632\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m gdf_buildings_osm \u001B[38;5;241m=\u001B[39m \u001B[43mgpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_file\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43morigin_data/5. Buildings_OSM\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto_crs(epsg\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32632\u001B[39m)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# 统一字段名用于对比（可选）\u001B[39;00m\n\u001B[0;32m     11\u001B[0m gdf_buildings[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcustom\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[1;32mD:\\STUDY\\anaconda3\\envs\\urban_morphology\\lib\\site-packages\\geopandas\\io\\file.py:294\u001B[0m, in \u001B[0;36m_read_file\u001B[1;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001B[0m\n\u001B[0;32m    291\u001B[0m             from_bytes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m engine \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpyogrio\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 294\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _read_file_pyogrio(\n\u001B[0;32m    295\u001B[0m         filename, bbox\u001B[38;5;241m=\u001B[39mbbox, mask\u001B[38;5;241m=\u001B[39mmask, columns\u001B[38;5;241m=\u001B[39mcolumns, rows\u001B[38;5;241m=\u001B[39mrows, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    296\u001B[0m     )\n\u001B[0;32m    298\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m engine \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfiona\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    299\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mapi\u001B[38;5;241m.\u001B[39mtypes\u001B[38;5;241m.\u001B[39mis_file_like(filename):\n",
      "File \u001B[1;32mD:\\STUDY\\anaconda3\\envs\\urban_morphology\\lib\\site-packages\\geopandas\\io\\file.py:547\u001B[0m, in \u001B[0;36m_read_file_pyogrio\u001B[1;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001B[0m\n\u001B[0;32m    538\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    539\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minclude_fields\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore_fields\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m keywords are deprecated, and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    540\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwill be removed in a future release. You can use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m keyword \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    543\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[0;32m    544\u001B[0m     )\n\u001B[0;32m    545\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minclude_fields\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 547\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pyogrio\u001B[38;5;241m.\u001B[39mread_dataframe(path_or_bytes, bbox\u001B[38;5;241m=\u001B[39mbbox, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\STUDY\\anaconda3\\envs\\urban_morphology\\lib\\site-packages\\pyogrio\\geopandas.py:265\u001B[0m, in \u001B[0;36mread_dataframe\u001B[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m use_arrow:\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;66;03m# For arrow, datetimes are read as is.\u001B[39;00m\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001B[39;00m\n\u001B[0;32m    263\u001B[0m     \u001B[38;5;66;03m# as numpy does not directly support timezones.\u001B[39;00m\n\u001B[0;32m    264\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatetime_as_string\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 265\u001B[0m result \u001B[38;5;241m=\u001B[39m read_func(\n\u001B[0;32m    266\u001B[0m     path_or_buffer,\n\u001B[0;32m    267\u001B[0m     layer\u001B[38;5;241m=\u001B[39mlayer,\n\u001B[0;32m    268\u001B[0m     encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[0;32m    269\u001B[0m     columns\u001B[38;5;241m=\u001B[39mcolumns,\n\u001B[0;32m    270\u001B[0m     read_geometry\u001B[38;5;241m=\u001B[39mread_geometry,\n\u001B[0;32m    271\u001B[0m     force_2d\u001B[38;5;241m=\u001B[39mgdal_force_2d,\n\u001B[0;32m    272\u001B[0m     skip_features\u001B[38;5;241m=\u001B[39mskip_features,\n\u001B[0;32m    273\u001B[0m     max_features\u001B[38;5;241m=\u001B[39mmax_features,\n\u001B[0;32m    274\u001B[0m     where\u001B[38;5;241m=\u001B[39mwhere,\n\u001B[0;32m    275\u001B[0m     bbox\u001B[38;5;241m=\u001B[39mbbox,\n\u001B[0;32m    276\u001B[0m     mask\u001B[38;5;241m=\u001B[39mmask,\n\u001B[0;32m    277\u001B[0m     fids\u001B[38;5;241m=\u001B[39mfids,\n\u001B[0;32m    278\u001B[0m     sql\u001B[38;5;241m=\u001B[39msql,\n\u001B[0;32m    279\u001B[0m     sql_dialect\u001B[38;5;241m=\u001B[39msql_dialect,\n\u001B[0;32m    280\u001B[0m     return_fids\u001B[38;5;241m=\u001B[39mfid_as_index,\n\u001B[0;32m    281\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    282\u001B[0m )\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_arrow:\n\u001B[0;32m    285\u001B[0m     meta, table \u001B[38;5;241m=\u001B[39m result\n",
      "File \u001B[1;32mD:\\STUDY\\anaconda3\\envs\\urban_morphology\\lib\\site-packages\\pyogrio\\raw.py:198\u001B[0m, in \u001B[0;36mread\u001B[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001B[0m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001B[39;00m\n\u001B[0;32m     60\u001B[0m \n\u001B[0;32m     61\u001B[0m \u001B[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    194\u001B[0m \n\u001B[0;32m    195\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    196\u001B[0m dataset_kwargs \u001B[38;5;241m=\u001B[39m _preprocess_options_key_value(kwargs) \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[1;32m--> 198\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mogr_read\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mget_vsi_path_or_buffer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_buffer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    203\u001B[0m \u001B[43m    \u001B[49m\u001B[43mread_geometry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mread_geometry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    204\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    205\u001B[0m \u001B[43m    \u001B[49m\u001B[43mskip_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    206\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_features\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    207\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwhere\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    208\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbbox\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    209\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_mask_to_wkb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    210\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    211\u001B[0m \u001B[43m    \u001B[49m\u001B[43msql\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    212\u001B[0m \u001B[43m    \u001B[49m\u001B[43msql_dialect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msql_dialect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    213\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_fids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_fids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdatetime_as_string\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdatetime_as_string\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    216\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mpyogrio\\\\_io.pyx:1240\u001B[0m, in \u001B[0;36mpyogrio._io.ogr_read\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpyogrio\\\\_io.pyx:220\u001B[0m, in \u001B[0;36mpyogrio._io.ogr_open\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mDataSourceError\u001B[0m: origin_data/5. Buildings_OSM: No such file or directory"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 读取数据\n",
    "# gdf_factories = gpd.read_file(\"path/to/your_processing_points.shp\").to_crs(epsg=32632)\n",
    "gdf_buildings = gpd.read_file(\"origin_data/5. Buildings\").to_crs(epsg=32632)\n",
    "gdf_buildings_osm = gpd.read_file(\"origin_data/5. Buildings_OSM\").to_crs(epsg=32632)\n",
    "\n",
    "# 统一字段名用于对比（可选）\n",
    "gdf_buildings['source'] = 'custom'\n",
    "gdf_buildings_osm['source'] = 'osm'\n",
    "\n",
    "# 合并两个数据源（用于对比绘图）\n",
    "gdf_compare = gpd.GeoDataFrame(pd.concat([gdf_buildings, gdf_buildings_osm], ignore_index=True), crs=gdf_buildings.crs)\n",
    "\n",
    "# 面积统计（单位：平方米）\n",
    "area_custom = gdf_buildings.geometry.area.sum()\n",
    "area_osm = gdf_buildings_osm.geometry.area.sum()\n",
    "\n",
    "# 数量统计\n",
    "count_custom = len(gdf_buildings)\n",
    "count_osm = len(gdf_buildings_osm)\n",
    "\n",
    "print(\"🏗️ 自有建筑数据：\")\n",
    "print(f\"建筑数量: {count_custom}\")\n",
    "print(f\"总建筑面积: {area_custom / 10000:.2f} 公顷\")\n",
    "\n",
    "print(\"\\n🗺️ OSM 建筑数据：\")\n",
    "print(f\"建筑数量: {count_osm}\")\n",
    "print(f\"总建筑面积: {area_osm / 10000:.2f} 公顷\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-19T11:39:42.181406Z",
     "end_time": "2025-05-19T11:39:45.023208Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置根目录名称\n",
    "root_dir = \"origin_data\"\n",
    "\n",
    "# 要创建的子文件夹列表（带编号与说明）\n",
    "folders = [\n",
    "    \"01_production_farming\",            # 农作物（可耕地）\n",
    "    \"02_production_aquaculture\",        # 水产养殖（海岸泻湖 + 河口）\n",
    "    \"03_production_livestock\",          # 畜牧养殖（草场）\n",
    "    \"04_transformation_industry\",       # 食品加工厂（GOOGLE 来源）\n",
    "    \"05_transformation_energy\",         # 水厂、电厂、供热等能源基础设施\n",
    "    \"06_logistics_transportation\",      # 公共交通 + 港口 + 仓储 + 配送中心\n",
    "    \"07_logistics_roads\",               # 可通行道路（MultiDiGraph）\n",
    "    \"08_supply_retail\",                 # 超市、市场、批发商等零售终端\n",
    "    \"09_supply_public_services\",        # 公共服务设施：学校、医疗、福利\n",
    "    \"10_built_environment\",             # 建成区信息（居住、商业、工业）\n",
    "    \"11_consumption_facilities\",        # 餐饮、酒店、住宿类消费终端\n",
    "    \"12_consumption_landuse_mix\",       # 土地混合度计算所需的 landuse 数据\n",
    "    \"13_waste_treatment\"                # 废弃物处理设施：垃圾厂、废水厂\n",
    "]\n",
    "\n",
    "# 批量创建文件夹\n",
    "for folder in folders:\n",
    "    path = os.path.join(root_dir, folder)\n",
    "    os.makedirs(path, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-23T11:50:48.570167Z",
     "end_time": "2025-05-23T11:50:48.588182Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 渲染图像"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box,Polygon,Point\n",
    "import os\n",
    "\n",
    "def square_buffer(center_point, half_size=500):\n",
    "    x, y = center_point.x, center_point.y\n",
    "    return box(x - half_size, y - half_size, x + half_size, y + half_size)\n",
    "\n",
    "building = gpd.read_file(\"processing_data/building_black\").to_crs(epsg=32632)\n",
    "farming = gpd.read_file(\"processing_data/farming_green\").to_crs(epsg=32632)\n",
    "processing = gpd.read_file(\"processing_data/processing_red\").to_crs(epsg=32632)\n",
    "road = gpd.read_file(\"processing_data/road_grey\").to_crs(epsg=32632)\n",
    "water = gpd.read_file(\"processing_data/water_blue\").to_crs(epsg=32632)\n",
    "\n",
    "processing_center = processing.unary_union.centroid\n",
    "\n",
    "output_dir = \"rendered_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# 4. 渲染函数：以一个点为中心，裁剪5km范围并渲染图像\n",
    "def render_one_image(center_point, index):\n",
    "    buffer = square_buffer(center_point, half_size=500)  # 250m 半径 = 500m 宽正方形\n",
    "\n",
    "    def clip_layer(gdf): return gdf[gdf.geometry.intersects(buffer)]\n",
    "\n",
    "    bld_clip = clip_layer(building)\n",
    "    farm_clip = clip_layer(farming)\n",
    "    proc_clip = clip_layer(processing)\n",
    "    road_clip = clip_layer(road)\n",
    "    water_clip = clip_layer(water)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_facecolor(\"white\")\n",
    "\n",
    "    # 顺序渲染\n",
    "    water_clip.plot(ax=ax, color='blue', edgecolor='none')\n",
    "    farm_clip.plot(ax=ax, color='green', edgecolor='none')\n",
    "    road_clip.plot(ax=ax, color='grey', linewidth=5)\n",
    "    bld_clip.plot(ax=ax, color='black', edgecolor='none')\n",
    "    proc_clip.plot(ax=ax, color='red')\n",
    "\n",
    "    ax.set_xlim(buffer.bounds[0], buffer.bounds[2])\n",
    "    ax.set_ylim(buffer.bounds[1], buffer.bounds[3])\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(output_dir, f\"render_{index:03d}.png\")\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 5. 遍历 processing 图层的每个 geometry（通常是 Polygon 或 Point）\n",
    "for idx, row in processing.iterrows():\n",
    "    center = row.geometry.centroid\n",
    "    render_one_image(center, idx)\n",
    "\n",
    "print(f\"✅ 共生成 {len(processing)} 张图，保存在 {output_dir}/ 中\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-20T13:54:26.885389Z",
     "end_time": "2025-05-20T13:55:43.014108Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "image_folder = \"rendered_images\"\n",
    "img_list = []\n",
    "\n",
    "for i in range(103):\n",
    "    img = Image.open(os.path.join(image_folder, f\"render_{i:03d}.png\")).resize((224, 224)).convert(\"RGB\")\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_list.append(img_array)\n",
    "\n",
    "img_array_all = np.stack(img_list)  # shape: (103, 224, 224, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-20T16:08:00.488636Z",
     "end_time": "2025-05-20T16:08:11.022716Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 使用预训练的 ResNet18\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Identity()  # 去掉分类头，保留特征输出\n",
    "model.eval()\n",
    "\n",
    "# 转换图像为 tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img in img_list:\n",
    "        x = transform(Image.fromarray((img * 255).astype(np.uint8)))\n",
    "        x = x.unsqueeze(0)  # batch 维度\n",
    "        feat = model(x).squeeze().numpy()\n",
    "        features.append(feat)\n",
    "\n",
    "X = np.stack(features)  # shape: (103, 512)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-20T16:08:20.257889Z",
     "end_time": "2025-05-20T16:11:17.497653Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_clusters = 3  # 你可以试着调成 3～6\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "labels = kmeans.fit_predict(X)\n",
    "\n",
    "\n",
    "X_tsne = TSNE(n_components=2, random_state=42).fit_transform(X)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_tsne[:,0], X_tsne[:,1], c=labels, cmap='Set2')\n",
    "plt.title(\"CNN-based Patch Clustering\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-20T16:40:05.499861Z",
     "end_time": "2025-05-20T16:40:05.875179Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
